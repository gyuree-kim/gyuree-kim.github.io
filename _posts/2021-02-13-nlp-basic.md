---
title: "[nlp] 자연어처리 기초 개념"
date: 2021-02-13 17:50
categories: nlp
---

- 참고문서([https://wikidocs.net/21667](https://wikidocs.net/21667))를 요약 및 정리
- 2021-02-13 22:40 updated.<br><br>


# 자연어처리 개념

- `자연어(Natural Language)` 일상 생활에서 사용하는 언어
- `자연어 처리(Natural Language Processing, NLP)` 자연어 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일
- **응용 분야** 음성 인식, 내용 요약, 번역, 사용자의 감성 분석, 텍스트 분류 작업(스팸 메일 분류, 뉴스 기사 카테고리 분류), 질의 응답 시스템, 챗봇 등<br><br>

# 개발 환경 구축

- 개발 환경은 `아나콘다` 또는 `구글 코랩`을 이용
    - `구글 코랩`([google colab](https://colab.research.google.com/)) : 주피터 노트북 형식의 웹 기반 환경. 별도 로컬  구축 필요 없음.
    - `아나콘다`([anaconda](https://www.anaconda.com/distribution/)) : 로컬 개발 환경. 파이썬 패키지를 쉽게 설치 가능
        - 공식 홈페이지에서 다운로드 후, 아래 명령어를 통해 최신 버전으로 업데이트

        ```php
        conda update -n base conda
        conda update --all
        ```

        - `Numpy`, `Pandas`, `Jupyter notebook`, `scikit-learn`, `matplotlib`, `seaborn`, `nltk` 등은 이미 설치되어 있음. 아나콘다에 미포함된 `tensorflow`, `keras`, `gensim`만 `pip`로 설치 필요.
        - `tensorflow` 구글의 머신 러닝 오픈소스 라이브러리

        ```python
        # install tensorflow lib
        pip install tensorflow

        # confirm if it is installed.
        ipython 
        ...
        In [1]: import tensorflow as tf
        In [2]: tf.__version__
        Out[2]: '2.0.0' // check the version installed
        ```

        - `keras` 텐서플로우에 대한 추상화 된 API를 제공

        ```python
        # install keras
        pip install keras

        # confirm if it is installed.
        ipython
        ...
        In [1]: import keras
        In [2]: keras.__version__ // check the version installed
        ```

        - `gensim` 머신 러닝을 사용하여 토픽 모델링과 자연어 처리 등을 수행할 수 있게 해주는 오픈 소스 라이브러리

        ```python
        #install gensim
        pip install gensim

        # confirm if it is installed.
        > ipython
        ...
        In [1]: import gensim
        In [2]: gensim.__version__
        Out[2]: '3.8.1' // check the version installed
        ```

        - `scikit-learn`과 `jupyter notebook` 설치: 아나콘다는 기본으로 설치되어 있음.

        ```python
        pip install scikit-learn
        pip install jupyter
        jupyter notebook //execute jupyter notebook. If it's not working, then go to "localhost:8888".
        ```
        <br>

## 자연어 처리를 위한 라이브러리: NLTK, koNLPy

- `NLTK` 자연어처리를 위한 파이썬 패키지. 다운로드 시 에러 발생할 경우 [여기](https://wikidocs.net/22488) 참고.

    ```python
    pip install nltk

    ipython
    ...
    In [1]: import nltk
    In [2]: nltk.__version__
    Out[2]: '3.4.5'
    In [3]: nltk.download() // Download data 
    ```

- `koNLPy` 한국어 자연어 처리를 위한 형태소 분석기 패키지. Java로 구성되어 있으므로 JDK 1.7 이상의 버전과 JPype가 설치되어 있어야 함. JDK 설치([https://www.oracle.com/technetwork/java/javase/downloads/index.html](https://www.oracle.com/technetwork/java/javase/downloads/index.html)) 후 환경변수 설정도 잊지 말자. JPype는 Java와 Python을 연결해주는 역할을 담당한다.

    ```php
    pip install JPype1‑0.6.3‑cp36‑cp36m‑win_amd64.whl
    ```
<br>

## 데이터 분석을 위한 라이브러리: Pandas, Numpy, Matplotlib

- `Pandas` 파이썬 데이터 처리를 위한 라이브러리. (참고:  [http://pandas.pydata.org/pandas-docs/stable/](http://pandas.pydata.org/pandas-docs/stable/)) 보통 pd로 import 하는 것이 관례이다.

### Pandas 데이터 구조 3가지: Series, DataFrame, Panel

- `Series` 1차원 배열의 값(values)에 각 값에 대응되는 인덱스(index)를 부여

    ```python
    sr = pd.Series([17000, 18000, 1000, 5000],
            index=["피자", "치킨", "콜라", "맥주"])
    print(sr)
    ```

    ```python
    피자    17000
    치킨    18000
    콜라     1000
    맥주     5000
    dtype: int64
    ```

    ```python
    print(sr.values) #[17000 18000  1000  5000]
    print(sr.index) #Index(['피자', '치킨', '콜라', '맥주'], dtype='object')
    ```

- `DataFrame` 2차원 리스트를 매개변수로 전달.열(columns), 인덱스(index), 값(values)으로 구성됨.

    ```python
    values = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    index = ['one', 'two', 'three']
    columns = ['A', 'B', 'C']

    df = pd.DataFrame(values, index=index, columns=columns)
    print(df)
    ```

    ```python
                    A  B  C
    one    1  2  3
    two    4  5  6
    three  7  8  9
    ```

    ```python
    print(df.index) # Index(['one', 'two', 'three'], dtype='object')
    print(df.columns) # Index(['A', 'B', 'C'], dtype='object')
    print(df.values) # result is below.
    ```

    ```python
    [[1 2 3]
        [4 5 6]
        [7 8 9]]
    ```

- `DataFrame`은 `리스트(List)`, `시리즈(Series)`, `딕셔너리(dict)`, `Numpy`의 `ndarrays`, 또 다른 데이터프레임으로 생성할 수 있음.
- `DataFrame` 조회

    ```python
    df.head(n) # 앞 부분을 n개만 보기
    df.tail(n) # 뒷 부분을 n개만 보기
    df['열이름'] # 해당되는 열을 확인
    ```

### 외부 데이터 읽기

- `Pandas`는 `CSV`, `텍스트`, `Excel`, `SQL`, `HTML`, `JSON` 등 다양한 데이터 파일을 읽고 데이터 프레임을 생성할 수 있음.

    ```python
    df=pd.read_csv('example.csv 파일의 경로') # example.csv 파일 읽기
    print(df)
    print(df.index)
    ```
<br> 

### Numpy

- 수치 데이터를 다루는 파이썬 패키지. 편의성뿐만 아니라, 속도면에서도 순수 파이썬에 비해 압도적으로 빠르다는 장점이 있음.

    ```python
    pip install numpy # how to install numpy when you don't have anaconda
    import numpy as np
    ```

- 주요 모듈 5가지

    ```python
    np.array() # 리스트, 튜플, 배열로 부터 ndarray를 생성
    np.asarray() # 기존의 array로 부터 ndarray를 생성
    np.arange() # range와 비슷
    np.linspace(start, end, num) # [start, end] 균일한 간격으로 num개 생성
    np.logspace(start, end, num) # [start, end] log scale 간격으로 num개 생성
    ```

- `np.array()` 리스트, 튜플, 배열로 부터 ndarray를 생성. index는 0에서 시작함.

    ```python
    a = np.array([1, 2, 3, 4, 5]) # 리스트로 1차원 배열 생성
    b = np.array([[10, 20, 30], [ 60, 70, 80]]) # 2차원 배열 생성
    ```

    ```python
    print(a.ndim) #차원 출력
    print(a.shape) #크기 출력
    ```

    ```python
    # ndarray 초기화
    a = np.zeros((2,3)) # 모든값이 0인 2x3 배열 생성.
    a = np.ones((2,3)) # 모든값이 1인 2x3 배열 생성.
    a = np.full((2,2), 7) # 모든 값이 특정 상수인 배열 생성. 이 경우에는 7.
    a = np.eye(3) # 대각선으로는 1이고 나머지는 0인 2차원 배열을 생성.
    a = np.random.random((2,2)) # 임의의 값으로 채워진 배열 생성
    ```

- `np.arange()` 지정해준 범위에 대해서 배열을 생성

    ```python
    # format
    numpy.arange(start, stop, step, dtype)
    a = np.arange(n) # 0, ..., n-1까지 범위의 지정.
    a = np.arange(i, j, k) # i부터 j-1까지 k씩 증가하는 배열.
    ```

    ```python
    # reshape()를 통해 0~29로 숫자를 생성한 후 다차원(5X6)으로 변경
    a = np.array(np.arange(30)).reshape((5,6))
    print(a)
    ```

- **Slicing** 원소들 중 복수 개에 접근 가능

    ```python
    import numpy as np
    a = np.array([[1, 2, 3], [4, 5, 6]])
    b=a[0:2, 0:2]
    print(b)
    ```

    ```python
    # result of 'print(b)'
    [[1 2]
        [4 5]]
    ```

    ```python
    b=a[0, :] # 첫번째 행 출력
    b=a[:, 1] # 두번째 열 출력
    ```

- **배열 연산** 연산자 +, -, *, / 또는 add(), subtract(), multiply(), divide() 함수 사용.

    ```python
    b = x + y  # b = np.add(x, y)와 동일
    b = x - y  # b = np.subtract(x, y)와 동일
    b = b * x  # b = np.multiply(b, x)와 동일
    b = b / x  # b = np.divide(b, x)와 동일
    ```

    ```python
    c = np.dot(a, b)  # 벡터와 행렬의 곱 또는 행렬곱
    ```

<br>

### Matplotlib

    - 데이터를 차트(chart)나 플롯(plot)으로 시각화(visulaization)하는 패키지

    ```python
    pip install matplotlib
    ```

    ```python
    %matplotlib inline
    import matplotlib.pyplot as plt
    ```

- **line plot**

    ```python
    plt.title('test') # 그래프 제목
    plt.plot([1,2,3,4],[2,4,8,6]) #(1,2), (2,4), (3,8), (4,6)을 지나는 선 그래프
    plt.show() # 그래프 출력

    plt.xlabel('hours') # x축 이름 설정
    plt.ylabel('score') # y축 이름 설정
    ```

- 여러개의 plot 사용

    ```python
    plt.title('students')
    plt.plot([1,2,3,4],[2,4,8,6])
    plt.plot([1.5,2.5,3.5,4.5],[3,5,8,10]) #라인 새로 추가
    plt.xlabel('hours')
    plt.ylabel('score')
    plt.legend(['A student', 'B student']) #범례 삽입
    plt.show()
    ```

### Padas Profiling

- 데이터의 성격을 파악하는 과정
- **EDA(Exploratory Data Analysis, 탐색적 데이터 분석)** 데이터 내 값의 분포, 변수 간의 관계, Null 값과 같은 결측값(missing values) 존재 유무 등 데이터를 파악하는 과정
- 참고: [https://wikidocs.net/47193](https://wikidocs.net/47193)

    ```python
    # install the package
    pip install -U pandas-profiling
    ```

    ```python
    # 파일 불러오기(다운로드 링크: https://www.kaggle.com/uciml/sms-spam-collection-dataset)
    import pandas as pd
    import pandas_profiling
    data = pd.read_csv('spam.csv 파일의 경로',encoding='latin1')
    ```

    ```python
    # 리포트 생성
    pr=data.profile_report() # 프로파일링 결과 리포트를 pr에 저장
    # data.profile_report() # 바로 결과 보기
    pr.to_file('./pr_report.html') # pr_report.html 파일로 저장
    ```

    ```python
    # 리포트 확인
    pr # pr에 저장했던 리포트 출력
    ```

<br><br>

## 머신 러닝 워크플로우(Machine Learning Workflow)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/02bcb2cc-4ed6-41b7-961c-03f99582f2f4/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/02bcb2cc-4ed6-41b7-961c-03f99582f2f4/Untitled.png)

### 단계1. 수집(Acquisition)

- 학습 데이터 수집하는 과정. 텍스트 데이터 파일 형식은 txt 파일, csv 파일, xml 파일 등 다양.
- **말뭉치 또는 코퍼스(corpus)** 자연어 처리에 필요한 자연어 데이터

### 단계2. 점검 및 탐색(Inspection and exploration)

- 탐색적 데이터 분석(Exploratory Data Analysis, EDA) 단계
- 데이터의 구조, 노이즈 데이터, 머신 러닝 적용을 위해서 데이터를 어떻게 정제해야하는지 등을 파악
- 독립 변수, 종속 변수, 변수 유형, 변수의 데이터 타입 등을 점검하며 데이터의 특징과 내재하는 구조적 관계를 알아내는 과정

### 단계3. 전처리 및 정제(Preprocessing and Cleaning)

- 머신 러닝 워크플로우에서 가장 까다로운 작업 중 하나.
- 토큰화, 정제, 정규화, 불용어 제거 등의 단계를 포함.

### 단계4. 모델링 및 훈련(Modeling and Training)

- 머신 러닝에 대한 코드를 작성하는 단계
- 전처리가 완료 된 데이터를 머신 러닝 알고리즘을 통해 기계에게 학습(training)시킴.
- (주의) 과적합(overfitting) 상황을 막기 위해 데이터 중 일부는 테스트용으로 남겨두고 훈련용 데이터만 훈련에 사용해야한다!

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6bb699f1-ba66-40a9-a6e9-4882b0fa1918/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6bb699f1-ba66-40a9-a6e9-4882b0fa1918/Untitled.png)

- 훈련 vs 검증 vs 테스트: 수능 시험에 비유하자면 훈련용은 학습지, 검증용은 모의고사, 테스트용은 수능 시험
- 검증용 데이터: 현재 모델의 성능. 즉, 기계가 훈련용 데이터로 얼마나 제대로 학습이 되었는지를 판단하는 용으로 사용. 모델의 성능을 개선하는데 사용.
- 테스트용 데이터: 모델의 최종 성능을 평가하는 데이터. 모델의 성능을 수치화하여 평가하기 위해 사용됨.

### 단계5. 평가(Evaluation)

- 기계가 예측한 데이터가 테스트용 데이터의 실제 정답과 얼마나 가까운지를 측정

### 단계6. 배포(Deployment)

- 평가 단계에서 기계가 성공적으로 훈련이 된 것으로 판단된다면, 완성된 모델을 배포.
- 완성된 모델에 대한 전체적인 피드백에 대해서 모델을 변경해야하는 상황이 온다면 다시 처음부터 돌아가야 하는 상황이 발생할 수 있음.(실제로는 거의 모든 단계에서 전 단계로 돌아갈 수 있음.)